version: '2.2'

services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - streaming

  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    ports:
      - 9201:9201
    networks:
      - streaming

  kib01:
    image: docker.elastic.co/kibana/kibana:7.9.1
    container_name: kib01
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://es01:9200
      ELASTICSEARCH_HOSTS: http://es01:9200
    networks:
      - streaming

  nifi:
    container_name: nifi
    image: apache/nifi:latest
    restart: unless-stopped
    volumes:
      - /Users/Yamada/Git/git-projects/modern_data_lake/infra/elastic_stack/dev/nifi:/nifi
    ports:
      - "8081:8081"
    environment:
      - NIFI_WEB_HTTP_PORT=8081
    depends_on:
      - es01
      - es02
    networks:
      - streaming

  zookeeper:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
        "sh", "-c",
        "bin/zookeeper-server-start.sh config/zookeeper.properties"
    ]
    ports:
        - "2181:2181"
    environment:
        LOG_DIR: /tmp/logs
    networks:
        - streaming
        
  kafka:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
        "sh", "-c",
        "bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} --override num.partitions=$${KAFKA_NUM_PARTITIONS}"
    ]
    depends_on:
        - zookeeper
    ports:
        - "9092:9092"
    environment:
        LOG_DIR: "/tmp/logs"
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
        KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        KAFKA_NUM_PARTITIONS: 3
    networks:
        - streaming

  kafdrop:
    image: obsidiandynamics/kafdrop
    environment:
        KAFKA_BROKERCONNECT: kafka:9092
    ports:
        - 9000:9000
    depends_on: 
        - kafka
    networks:
        - streaming

  event-producer:
    image: lyamada-docker/valorant-matches-event-producer-jvm
    environment:
        KAFKA_BROKERS: kafka:9092
    ports:
        - 8080:8080
    depends_on: 
        - kafka
    networks:
        - streaming

volumes:
  data01:
    driver: local
  data02:
    driver: local
    
networks:
  streaming:
    driver: bridge